{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep image prior Keras implementation\n",
    "\n",
    "The goal of this notebook is to implement the denoising algorithm of the paper [Deep Image Prior](https://arxiv.org/abs/1711.10925) which consists in using randomly initialized neural network as priors to remove the noise from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import Add\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_size = 257\n",
    "perturbation_max = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess = lambda x : x / 127 - 1\n",
    "deprocess  = lambda x :((x + 1) * 127).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load an image and apply a uniform random noise to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(PIL.Image.open('dog.png'))\n",
    "preproc_img = preprocess(img)\n",
    "image_shape = img.shape\n",
    "plt.imshow(deprocess(preproc_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption = np.random.randint(-perturbation_max, perturbation_max, size = image_shape)\n",
    "corrupted_img = (img + corruption).clip(0, 255)\n",
    "preproc_corrupted_img = preprocess(corrupted_img)\n",
    "plt.imshow(deprocess(preproc_corrupted_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's build a simple convolutional autoencoder with an hyperbolic tangent activation as final steps of the encoder and decoder. We use this activation function to easily ensure that our final pixel values will be in the [-1, 1] interval. In the paper, the authors mention that they use strided convolutions instead of pooling layers but we first wanted to try this approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_input = Input(shape = image_shape)\n",
    "conv1       = Convolution2D(32, 3, padding = 'same', activation = 'relu')(model_input)\n",
    "conv2       = Convolution2D(32, 3, padding = 'same', activation = 'relu')(conv1)\n",
    "#pool1       = AveragePooling2D()(conv2)\n",
    "strided_conv1 = Convolution2D(32, 3, strides = (2, 2), padding = 'same')(conv2)\n",
    "conv3       = Convolution2D(64, 3, padding = 'same', activation = 'relu')(strided_conv1)\n",
    "conv4       = Convolution2D(64, 3, padding = 'same', activation = 'relu')(conv3)\n",
    "#pool2       = AveragePooling2D()(conv4)\n",
    "strided_conv2 = Convolution2D(64, 3, strides = (2, 2), padding = 'same')(conv4)\n",
    "conv5       = Convolution2D(128, 3, padding = 'same', activation = 'relu')(strided_conv2)\n",
    "conv6       = Convolution2D(128, 3, padding = 'same', activation = 'relu')(conv5)\n",
    "flatten     = Flatten()(conv6)\n",
    "encoding    = Dense(encoding_size, activation = 'relu')(flatten)\n",
    "dense2      = Dense(192, activation = 'relu')(encoding)\n",
    "reshape     = Reshape((8, 8, 3))(dense2)\n",
    "upsample2   = UpSampling2D(size = (4, 4))(reshape)\n",
    "conv11      = Convolution2D(128, 3, padding = 'same', activation = 'relu')(upsample2)\n",
    "conv12      = Convolution2D(128, 3, padding = 'same', activation = 'relu')(conv11)\n",
    "add1        = Add()([conv12, conv6])\n",
    "upsample3   = UpSampling2D()(add1)\n",
    "conv13      = Convolution2D(64, 3, padding = 'same', activation = 'relu')(upsample3)\n",
    "conv14      = Convolution2D(64, 3, padding = 'same', activation = 'relu')(conv13)\n",
    "# add2        = Add()([conv14, conv4])\n",
    "upsample3   = UpSampling2D()(conv14)\n",
    "conv15      = Convolution2D(8, 3, padding = 'same', activation = 'relu')(upsample3)\n",
    "conv16      = Convolution2D(3, 3, padding = 'same', activation = 'tanh')(conv15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(model_input, conv16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compile the model and associate an Adam optimizer with a quite high learning rate (0.01). It is mentioned in the paper that higher learning rates usually produce higher quality outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(Adam(1e-3), loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the training of the network, we start with a base image initialized randomly and train the neural network to transform it into our corrupted image. Note the the neural network has not been trained on any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_image = np.random.random(size = (1,) + image_shape) * 2 - 1\n",
    "corrupted_img_batch = np.expand_dims(preproc_corrupted_img, 0)\n",
    "fit_params = {\n",
    "    'x': base_image,\n",
    "    'y': corrupted_img_batch,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 1,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(**fit_params)\n",
    "img_pred = autoencoder.predict(base_image)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.fit(**fit_params)\n",
    "# img_pred = autoencoder.predict(corrupted_img_batch)\n",
    "# plt.imshow(deprocess(img_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the original image (left), its corrupted counterpart (center) and the denoised result obtained from the corrupted image (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(deprocess(preproc_corrupted_img))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(deprocess(img_pred[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
